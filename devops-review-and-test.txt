1.) <<<<< Why Devops?


Q: Why do we use DevOps?


A: We use DevOps to increase efficiency between the Development Team and the Operations Team by using Continuous Integration and quick releases to improve the collaboration.




2.) <<<<< Traditional IT vs DevOps


 Q: What are some of the differences between IT and DevOps?


A: 
* IT can be less productive, while DevOps is considered more productive.
* IT has a skills centric team, while the DevOps can be broken up into specialties. If someone knows Kubernetes well and another knows Git well, the two collaborate instead of a "everyone knows everything" situation.
* IT invests more time in planning, where DevOps uses smaller and more frequent releases that lead to easy scheduling and spending less time planning.
* IT has a difficult time achieving a target or goal (think big picture), where DevOps combines frequent releases with continuous feedback to constantly push updates.




3.) <<<<< What Is DevOps?


Q: What is DevOps?


A: DevOps is a software development methodology that improves collaboration between the Development Team and Operations Team using various automation tools.



https://www.evernote.com/shard/s457/res/1c1480ca-f5d1-44f3-8992-285af41ce4f8



Q:  Tell me about the DevOps life cycle, the steps and definitions.


A: 
{
    Dev: {
        Plan, Build, Code, Test 
    },
    Ops: {
        Release, Deploy, Operation, Monitor
    }
}


Plan what you have to do


Code your way in
 
Build your code
* If you have a Java file you will have to create a .jar file or .exe file out of that. This is called Building
 
Test your code
* Test the code for any faults in the functionalities. If there are no faults you move on to the next step.


Release the  code to the Ops team. There are two kinds of releases:
* Internal Release - Releasing the software to a different team of the company (see the image above).
* External Release -
 
Operations team will Deploy the software onto the target system. This could be a testing server (server will test or run automated tests) or the production server (testing has happened).
 
Operation can be done internally or be done by the customer. This stage is when we actually operate the software. Is it doing good when there is traffic, is it good when people are doing arbitrary tasks on the software.
 
Monitor consistently to see if tasks or application is functioning properly. If it is not functioning properly, you are making a log of what is happening.
 
If you get any kind of feedback from the Monitor stage, we start again from the top of the list by planning how to solve the problems we are getting in the Monitor stage.




Q: How does DevOps solve the problem between Development and Operations? 


A: They automate the life cycle. The Developer does not have to give his code to the Operations guy. It will be given through a tool (Docker). The Dev will enclose his code inside Docker and push it to the Ops team, and the Ops team will run Docker and the code should run fine.




4/5.) <<<<< DevOps Life Cycle / How DevOps Works


Q: What does SDLC stand for?


A: Software Development Life Cycle




Q: What are the five stages of the DevOps Life Cycle?


A: Continuous Development, Continuous Testing, Continuous Integration, Continuous Deployment, and Continuous Monitoring




Q: In what order does the life cycle usually operate?


A: Development, pushed to version control, picked up by Integration Tool, Deployed to Test server. If it does not pass the tests, it is sent to the Monitor tool and back to Development. If it does pass the tests, it is Deployed to the Production server, where the Monitor tool logs bugs and/or features the user may have.




Q: Explain the five stages of the DevOps Life Cycle.


A: 


Continuous Development
* This stage involves committing code to version control tools like Git for maintaining the different versions of the code, and uses tools like Ant, Maven, Gradle for building/packing the code into an executable file that can be forwarded to the QA's for testing
 
Continuous Integration
* The stage is a critical point in the whole DevOps Life Cycle. It deals with integrating the different stages of the DevOps Life Cycle, and is therefore the key in automating the whole DevOps process.
 
Continuous Deployment
* In this stage the code is built, the environment or the application is containerized and is pushed on to the desired server. The key processes in this stage are Configuration Management, Virtualization and Containerization. 
 
Continuous Testing
* The stage deals with automated testing of the application pushed by the developer. If there is an error, the message is sent back to the integration tool, this tool in turn notifies the developer of the error. If the test was a success, the message is sent to the Integration Tool which pushes the build on the production
 
Continuous Monitoring
* The stage continuously monitors the deployed application for bugs or crashes. It can also be setup to collect user feedback. The collected data is then sent to the developers to improve the application.




6.) <<<<< DevOps Tools


Q: What kinds of tools are used in DevOps, and where in the Life Cycle?


A:


Development: Git


Testing: Selenium


Integration: Jenkins


Deployment: Docker, Ansible, Puppet


Monitoring: Nagios




Q: Explain what these technologies do.


A: 


GitHub: Version control software, used to track changes in code and version changes.


Selenium: Open source software tool used to automate testing suites as soon as the build is put onto a machine.


Jenkins: Open source automation server, helps to automate the non-human part of the software development process, with Continuous Integration and facilitating technical aspects of Continuous Delivery.


Docker: A tool used to create images of an application, wrapping up all the dependencies of the project in a process called containerization that can be run on any machine that has Docker installed.


Puppet: A configuration management tool used to install system dependencies like Docker or Python, without having to touch the remote computer.


Nagios: A monitoring tool with a dashboard with all your services listed on it. These services can exist on any system outside the network or inside the network. All the services running on it can be seen inside the Nagios dashboard.




Q: Explain the DevOps Life Cycle using the tools you have listed above.


A: Developers use GitHub to make and track changes in the applications code. When changes are pushed, Jenkins picks up the build and sends it to the testing server. The server is configured using Puppet to install system dependencies, and Selenium to install and run the test suites. Once the tests pass, Jenkins again picks up the build and sends it to the production server, where Nagios monitors the application for errors and user feedback.



7.) <<<<< Introduction To Git


Q: What is Git?


A: Git is a version-control system for tracking changes in computer files and coordinating work on those files between multiple people.




Q: Tell me about some of the common git commands you use.


A:


git init - Creates repository on local system


git status - Check current status of repository


git add - Add and stage files for commit 


git commit - Once files are staged, they are ready to be committed and added to the git log. Last step before pushing.


git remote add origin <URL> - Set the origin of the repository on Github so  we can push our changes.


git push origin <branch-name> - Push our changes to a branch in our repository.


git clone <URL> - Creates a new folder with the name of the repository in the current directory you are git cloning to.


git pull - Pulls the latest changes from the repository.


git branch <name-of-new-branch> - Creates a branch with the current status of the branch you are on.


git branch -D <name-of-branch> - Deletes branch.


git checkout <name-of-branch> - Switches to branch.


git stash - Stashes your changes on a current  branch. Useful if you need to switch between branches in the middle of work without untracked files following you from branch to branch.


git stash pop - Adds the stashed files back to your branch once you have switched back.


git revert <commit-id> - Reverts to a previous commit. In git log you will actually see that it creates a new commit with a new commit id and has notes on the reversion.


git checkout <commit-id> - Allows you to go into previous commits without actually reverting.


git diff <commit-id-version-x> <commit-id-version-y> - Shows you the difference between two commits.


git log - Shows you a log of commits with the commit messages.



8.) <<<<< Problems Before Docker


Q: What are some of the problems before technologies like Docker?


A: When the Developer has to give his program to the Operations/Testing guy, he will then setup his environment the same way, same OS, Software, and Libraries. Even though the Ops guy did his best with installing everything, he still could not get the file to run correctly.




Q: How was this fixed?


A: The Developer writes in an environment that he is able to give to the Operation team for further testing and deploying on production. The Ops guy now doesn't have to worry about the OS, Software, or Libraries because everything is contained inside that wrapper environment. This is all made possible using software like Docker.




9.) <<<<< What is Docker?


Q: What is Docker?


A: Docker is a computer program that performs operating-system-level virtualization, known as "containerization".




Q: What is Application containerization?


A: Application containerization is an OS-level virtualization method used to deploy and run distributed applications without launching an entire virtual machine (VM) for each app.




Q: How does Docker work on a system?


A: Once you have your OS installed on a computer, you install the container engine. The container engine is nothing but the docker software that you would install on top of your OS. Once you install the container engine you can run any kind of container.




Q: Why are containers so small?


A: The container does not contain all the OS files. The container engine shares its space with the OS system. The container is void, the container shares the underlying kernel of the OS on which the container engine is installed. They don't need all the files of the OS, they just need the binaries required for the particular environment to work.




Q: What's the difference between Docker and VM?


A: In the case of containers, you have the bare minimum binaries or libraries. In the case of the VM's, you have the whole OS installed the size of the VM is much bigger. 




10.) <<<<< Docker Installation
 
N/A



11.) <<<<< Docker Container Life cycle


Q: Explain the Docker Container Life cycle.


A: First thing you do is pull the image from Docker onto your system. Your system is where Docker Engine is installed. What you download from Docker Hub is an image of a container. The next step you do is you run the image. This is the normal state of a container. The moment you run the image it  becomes a container. When you are done with a container, you can stop it. When you are done with everything, and you don't need the container anymore, you can delete it. This is the Life Cycle of Docker.
 
You pull from Docker Hub, it becomes an image. You then run that image, it becomes a container. Containers can either be in the running state, the stopped state, or the deleted state.




13.) <<<<< What is a "Dockerfile"?





Q: What is a Dockerfile?


A: A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession.




Q: What are the commands in a Dockerfile, and what do they do?


A: 


FROM - The FROM keyword is used to define the base image, on which we will be building.
 
ADD - The ADD keyword is used to add files to the container being built. 
 
RUN - The RUN keyword is used to add layers to the base image, by installing components. Each RUN statement adds a new layer to the docker image. The RUN keyword runs whatever commands in the terminal you are working in.
 
CMD - The CMD keyword is used to run commands on the start of the container. These commands run only when there is no argument specified while running the container.
 
ENTRYPOINT - The ENTRYPOINT keyword is used strictly run commands the moment the container initializes. The difference between CMD and ENTRYPOINT is, ENTRYPOINT will run irrespective of the fact whether argument is RUN is specified or not.
 
ENV - The ENV keyword is used to define environment variables in the container run-time.




Q: From a directory, how would you build your Dockerfile?


A: docker build . -t new_dockerfile
* To specify just a folder, or just a file, instead of . replace with ./some-folder-or-file-name



14.) <<<<< Introduction to Docker Volumes


Q: What is a Docker Volume?


A: Docker Volumes are used to persist data across the lifetime of a container.




Q: What are two ways to achieve this goal, and tell me about them?


A: 


Bind Mount
* docker run -it -v /home/ubuntu/dockerfile:/app -d ubuntu
* These files are not actually copied to the container, but mirrored. So any changes to the directory on your local computer will reflect on the docker container.
* Disadvantage: The file path must not change. For instance, all your files are mapped using a linux system. If someone downloads your image from Docker Hub on a Windows computer, the file path will not be the same.
 
Docker Volume
* Syntax: docker volume create test
* Once you have a volume, use the following syntax to attach to a container.
    * docker run -it --mount source=<name-of-volume>,target=<path-to-container-directory> -d <image-name>
    * docker run -it --mount source=test,target=/app -d ubuntu
* Once we exec into the container we made, we can make changes to that /app folder by adding files etc. If we then create a new container using the same mount source=<name-of-volume>, all containers made using the volume we have chosen will have these files. Any changes made in this directory will reflect across all containers. 
    * Note: When specifying the target on a new container, it does not have to be the same as the original. The only thing that has to be the same is the source variable for the container.
* You can move files into containers from your local file system using the following syntax (very useful for pushing files to volumes):
    * docker cp <file-path> <container-id>:<file-path-in-container>
    * docker cp ./2.html 519049c974b4:/app




Q: What is a Monolithic Application, and some of its disadvantages?


A: A monolithic application is a single-tiered software application in which different components are combined into a single program which resides in a single platform. If one component is written in a language like Java, the rest have to be written in Java.


Disadvantages of a Monolithic Application
 
* Application is large and complex to understand
* Entire Application has to be re-deployed on an application update
* Bug in any module, can bring down entire application
* Has a barrier to adopting new technologies






Q: What are Microservices, and some of their advantages?


A: Microservices are a software development architectural style that structures an application as a collection of loosely coupled services. Each component is segregated and functions independently, while still working together.


Advantages of Microservices
 
* Application is distributed hence easy to understand
* The code of only the Microservice which is supposed to be updated is changed
* Bug in one service does not affect other services
* No barrier to any specific technology




Q: What is Docker Compose?


A: Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to  configure your application's services. Then, with a single command, you create and start all the services from your configuration. Run docker-compose up and compose starts and runs your entire app. Microservices are actually not launched through docker-compose, they are put on something called a container orchestration tool.




Q: What is a container orchestration tool?


A: A container orchestration tool is when you have multiple containers you have launched, and one container goes down or is changed to a stop state. The orchestration tool will create another one in place, without the end user ever knowing what happened.



15.) <<<<< What is Docker Swarm?


Q: What is Docker Swarm, and what are it's advantages?


A: Docker Swarm is a clustering and scheduling tool for Docker containers. With Swarm, IT administrators and developers can establish and manage a cluster of Docker nodes as a single virtual system.
 
* You get the opportunity to monitor the health of containers.
* Helps you keep a number of specified healthy containers always in the running state.




Q: How would you go about deploying an App using Docker Swarm? Why is this great?


A: Containers on the cluster are deployed using services on Docker Swarm. A service is a long-running Docker container that can be deployed to any node worker.


This is great, because you can go to either the leaders IP:83 or the works IP:83 and you will be able to see your application. You can also docker rm -f $(docker ps -a -q) on either the worker or the leader, and if a container is ended a new one is automatically rebuilt so the app is not down. It will always maintain the specified number of replicas.



17.) <<<<< Puppet code basics




Q: What are a few puppet components?


A: The most basic component of Puppet Code is a resource. A resource describes something about the state of the system, such as a certain user or file should exist, or a package should be installed, etc.


resource_type {'resource_name':
 
    attribute => value,
            ...
}


package { 'nginx':
    ensure => 'installed',
}




Q: What is a Manifest?


A: Manifests are basically a collection of resource declarations, using the extension .pp


Must begin with node default
* node default{
* package {'nginx':
    * ensure => installed,
    * }
* file {'/tmp/status.txt':
    * content => 'Nginx Installed',
    * mode => '0644',           # permissions
    * }
* }




Q: Explain Variables in Puppet


A: Variables can be defined at any point in a manifest. The most common types of variables are strings and arrays of strings, but other types are also supported, such as booleans and hashes.
 
ex: 
 
$textVar = 'Test Text!'
 
{file '...':
    content => $textVar,
}




Q: Explain Loops in Puppet


A: Loops are typically used to repeat a task using different input values. For instance, instead of  creating 10 tasks for installing 10 different packages, you can create a single task and use a loop to repeat the task with all the different packages you want to install.
 
ex:
 
$packages = ['nginx','mysql-server']
 
package {$packages:
    ensure => installed,
}




Q: Explain Conditions in Puppet


A: Conditionals can be used to dynamically decide whether or not a block of code should be executed, based on a variable or an output from a command, for instance.
 
exec { "Test":
    command => '/bin/echo apache2 is installed > /tmp/status.txt,
    onlyif => 'bin/which apache2',
}
 
* Runs automatically if returns true
 
exec { "Test":
    command => '/bin/echo apache2 is not installed > /tmp/status.txt,
    unless => 'bin/which apache2',
}
 
* Runs automatically if returns false




18.) <<<<< What is Ansible?

Q: What is Ansible?


A: Ansible is an open-source configuration management tool.



https://www.evernote.com/shard/s457/res/6a2be3b4-28bf-4d13-b1c3-16fe3e9203a0




Q: What is ansible-playbook?


A: An organized unit of scripts that defines work for a server configuration written in YAML.


ex:


---
 - hosts: slave1
   sudo: yes
   name: play1
   tasks:
    - name: Install Apache
      apt: name: apache2 state=latest


Q: Walk me through the setup of an ansible-playbook YAML file, and setup with a slave.


A:


 Summary


Create first_playbook.yml using on your Master
* sudo apt install ansible
* sudo nano <playbookname>
    * Must begin with ---
    * Must specify hosts
        * "hosts" can have one host or a group of hosts from an inventory file
            * /etc/ansible/hosts
    * Each Play is like a dictionary and has name, hosts, tasks. Order doesn't matter.
    * The Playbook is like a dictionary of plays.
    * Similarly tasks are nothing but lists Denoted by -
    * For tasks ordered collection. Position of entry matters.
        * First entry gets performed first.
 


Make sure you have your ansible host file configured.
* sudo nano /etc/ansible/hosts and add this at the bottom 
* The slave1 / slave2 are the host names and can be configured as long as they match.
* [production] #specifies a tag, to be used if you would like in the YAML file
* <name-of-host-from-yaml> ansible_ssh_host=<public-ip-address>
* slave2 ansible_ssh_host=34.214.130.35




Q: How do you connect Masters and Slaves?


A: 


Master
* cd .ssh
* cat id_rsa.pub
    * Copy the ssh-rsa text
    * If you don't have id_rsa.pub, you need to create SSH Key. Follow EVERY step.
        * https://help.github.com/en/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent


Slave
* cd .ssh
* sudo nano authorized_keys
    * Paste in the copied text on a new line.


Master
* ssh ubuntu@<ip-or-dns>
* exit
    * Leave the slave environment
* sudo nano /etc/ansible/hosts
    * Scroll down and add 
    * slave<number> ansible_ssh_host=<slave-public-ip>
* ansible -m ping all
    * Not necessary, but useful.
* Now you can make changes to your play.yml file for the new host, just be it's the same host name you gave it in the /etc/ansible/host file.




Q: How would you add a script from your master to your play.yml?


A:
* cd ~/ansible
* nano hello.sh
    * #!/bin/sh
    * echo hello world > /var/www/html/1.html
* nano play.yml
    * - name: Adding Website
    *   script: hello.sh
* ansible-playbook play.yml
 
Any time you make changes to that script file, and run ansible-playbook, the changes are updated on the slave that has the file.




19.) <<<<< Introduction to Software Testing


Q: What is Software Testing?


A: Software testing is defined as an activity to check whether the actual results match with the expected results to ensure that the software system is defect free.




Q: What are the types of Software Testing?


A: 
Automated Testing
* Test cases are executed automatically
* More accurate
* More suitable when test cases are run repeatedly
* Suitable for scenarios when testing is functionality based
 
Manual Testing
* Test cases are executed manually
* Less accurate
* More suitable when test cases are supposed to run only once or twice
* More suitable when testing is for user experience




Q: What are some of the tools used in Software Testing?


A: 
* Selenium
* Appium
* Cucumber
* Test Studio




20.) <<<<< Introduction to Selenium


Q: What is Selenium, and how does it differ from TestNG?


A: Selenium is a portable framework for testing web applications. Selenium provides a playback tool for authoring functional tests without the need to learn a new test scripting language. Selenium is used for finding the element, for doing any actions.




Q: What are the components of Selenium?


A: 
* Selenium RC
    * Due to same origin policy, testers had to install Selenium Core and the web server on their local system
    * This was done to keep the domain same for the Selenium Core and the web application to be tested.
    * Selenium RC is a web server, which acts as an HTTP proxy.
    * It tricks the OS into believing both Selenium Core and the website to be tested are on the same domain.
    * This system was also known as Selenium 1.
* Selenium IDE
    * Selenium IDE was originally created as a Firefox extension.
    * It could automate tests using the record and playback feature.
    * The intention behind creating this component was to increase the speed of creating test cases in Selenium.
* Selenium Grid
    * Selenium Grid enables parallel testing of applications on multiple machines.
    * It was primarily created to minimize the time taken in executing test cases.
    * It can be used across multiple browsers and OS.
    * It can also be used to break down a huge test suite among many computers testing the same application
* WebDriver
    * Selenium WebDriver was the first cross-platform testing  framework that could control the browser from the OS level.
    * It was developed in 2006, when web applications and browsers were becoming more powerful and restrictive with JavaScript programs like Selenium Core.
    * It was better than Selenium IDE and RC.
    * It controls the browser by directly communicating with it.




Q: What is Maven?


A: Maven is a build automation tool used primarily for Java projects. Maven addresses two aspects of building software: first, it describes how a software is built and, second, it describes its dependencies.




Q: Why do we need Maven?


A: 
* Maven is used to download dependencies for a software program.
* Dependencies to be downloaded are included inside a POM.xml file.
* Once the dependencies are added in the POM file, simply save the project and all the dependencies will automatically be downloaded.




21.) <<<<< Create Automated Tests in Selenium


Q: What are the steps to executing a web test?


A: 
* Find the element on the web browser
* Perform an action on the found element(s)
* Test and create a test report with the results
    * Find element, Perform action, Test & Report




Q: How do you find elements in Selenium?


A: An element can be found on a web page using the following selectors:
* ID
* Name
* Class Name
* Tag Name
* Link Text
* Partial Link Text
* XPATH
 
Syntax: WebElement button = driver.findElement(By.class("CwaK9"));




Q: How do you perform actions on these elements?


A: Using these methods, we can automate user interaction with elements in the browser.


* click(): Used to click on the link and wait for page load to complete before proceeding to the next command
* sendKeys(): Used to enter values onto text boxes
* clear(): Used to clear text boxes of its current  value
* submit(): WebDriver will automatically trigger the submit function of the form where that element belongs to
    * WebElement button = driver.findElement(By.class("CwaK9")).click();




22.) <<<<< Features of TestNG


Q: What is TestNG, and how does it differ from Selenium?


A: TestNG is an open-source automated testing framework, where NG means "Next Generation". It is a testing framework inspired from JUnit and NUnit, but introducing some new functionalities makes it more powerful and easier to use. TestNG performs a check to return whether a test was right or wrong.




Q: What are some of the features of TestNG?


A:  
* TestNG annotations are easy to create test cases. 
* Test cases can be grouped and prioritized more easily.
* It supports parameterization.
* It supports data-driven testing using DataProviders.
* It generates HTML reports.
* Parallel test execution is possible.
* it readily supports integration with other tools like plug-ins like Eclipse IDE, build tools Ant, Maven etc.




23.) <<<<< Annotations in TestNG


Q: What are Annotations in TestNG (Also used in Java)?


A: Annotations in TestNG are used to decide the flow of the program. There are a lot of annotations in TestNG, we will focus on the most used ones and following are the same:
* @BeforeSuite: The annotated method will be run only once before all tests in this suite have run
* @BeforeTest: The annotated method will be run before any test method belonging to the classes inside the <test> tag is run.
* @BeforeClass: The annotated method will be run only once before the first test method in the current class is invoked.
* @BeforeMethod: The annotated method will be run before each test method.
    * This is before your test method is run.
* @AfterMethod: The annotated method will be run after each test method.
    * This is after your test method is run.
* @Test: This marks a class or method as part of the test.
* @AfterTest: The annotated method only runs after the test suite.
    * This is because the @BeforeTest only runs once.




Q: What is Continuous Testing?


A: Continuous Testing is the process of executing automated tests as part of the software delivery pipeline in order to obtain feedback on the business risks associated with a software release candidate as rapidly as possible.


* Commit on github
    * Triggers Jenkins
        * Deploys To Test Server
            * Test Server runs tests on this application
            * Get a failure or pass message
                * This is the Continuous Testing part of the DevOps Life cycle.
                * Failure means you rewrite your code
                * Feedback is given back to developer through Continuous Monitoring
            * Get a Pass
                * Set a trigger for a manager to review, then pushes to production
                * On success, can be automatically pushed to production


Products are built with their respective test suites while the features are being developed.
 
Production Server
* Product Features
    * Feature A
 
Testing Server
* Test Suite
    * Test suite for Feature A
 
If we have a new Feature, lets call it Feature B, we need a new Test Suite for Feature B
 
When Developer pushes Feature A, Feature A gets tested. Same with Feature B.
 
It is very important to update your Testing Suites with all the New Feature Tests as and when the new Feature is being developed.





24.) <<<<< Continuous Integration in Jenkins





Q: What is Continuous Integration?


A: The process of having shorter release cycles (sometimes several times a day) i.e. creating small features and integrating them to the source code, and employing automated build and test processes for quicker feedback.




Q: What were some of the problems before Continuous Integration?


A: 
* Infrequent Commits led to bigger releases in one go leading to complex integration
* Manual Testing took a lot of time
* Feedback took a lot of time to reach Developer
* High risk and uncertainty




Q: What are some of the advantages of Continuous Integration?


A: 
* Frequent Commits hence smaller feature release
* Automated Build and Testing
* Instant Feedback to Developer
* Low risk and Faster Delivery




Q: What is Jenkins?


A: Jenkins is an open source automation server written in Java. Jenkins helps to automate the non-human part of the software development process, with continuous integration and facilitating technical aspects of continuous delivery.




Q: What is the Jenkins Master Worker Architecture?


A:
* Jenkins Master-Worker architecture is important to accomplish Continuous Deployment
* Jenkins Workers don't need to have Jenkins installed on them
* Useful in scenarios where it distributes the load when we have parallel and complex builds


Jenkins becomes your Master server, Testing server becomes the Worker server for Jenkins. Similarly, your Production server would become a Worker server for Jenkins.
 
The Master Jenkins will only have the Jenkins installation. Jenkins will not have to be installed on any other systems that are serving as a Worker.



25/26.) <<<<< Why Kubernetes / What is Kubernetes?


Q: What is Kubernetes?


A: Kubernetes being a container orchestration tool, is used when our application is distributed in multiple containers. Its job is to monitor, scale, and restart automatically even if they are spread across multiple nodes.




Q: What would happen if we didn't have Kubernetes?


A: 
* Each services monitoring is difficult.
* Scaling a Particular service based on load is not possible.
* Too much manual intervention required for managing containers.
* Managing containers on multiple servers becomes difficult.




Q: What are some features of Kubernetes?


A: 
* Load balancing
* Health checks
* Managing multiple containers as one entity
* Resource usage monitoring
* Networking
* Rolling update




Q: How does Kubernetes work?


A: You have a Master with several nodes inside the Master. The job of the Master is to schedule containers on the Nodes, monitor the Nodes, monitor the containers running in the Nodes, and keep track of the logs.
 
The Master plays the role of Monitoring everything, of Scheduling everything while the Workers (Nodes) have the job of processing whatever it is required in your application (processing, sending API calls, etc). 
 
Kubernetes is running on both the Master and the Nodes. This allows them to interact as if they were one whole system.
 
It's very easy to add more Nodes to the cluster, to an existing cluster it can be done very quickly. Once you have your Master instantiated, you get a command to add new Nodes. All you have to do is install Kubernetes on that node and run the command to add it to the cluster.




27.) <<<<< Why Kubernetes / What is Kubernetes?








































